{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion( week 2) .ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swarnendu111/Basic-ML-and-DA-in-python-R/blob/master/Fashion(_week_2)_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "qnyTxjK_GbOD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#  A Computer Vision Example\n",
        "\n",
        "But what about a scenario where writing rules  is much more difficult -- for example a computer vision problem? Let's take a look at a scenario where we can recognize different items of clothing, trained from a dataset containing 10 different types."
      ]
    },
    {
      "metadata": {
        "id": "YAxht804nSqt",
        "colab_type": "code",
        "outputId": "460ef5d7-ed92-4a20-8fc6-97c0a8326a35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n_n1U5do3u_F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The Fashion MNIST data is available directly in the tf.keras datasets API. load it like this:"
      ]
    },
    {
      "metadata": {
        "id": "Mqd4e0uYh_30",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images , training_labels) , (test_images , test_labels) =fashion_mnist.load_data()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qJ9Rh27k0a_B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "print a training image, and a training label to see...Experiment with different indices in the array"
      ]
    },
    {
      "metadata": {
        "id": "vWPTAXa-oGwU",
        "colab_type": "code",
        "outputId": "f632e413-feea-4ad6-c30b-682b0911590a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1300
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(training_images[5500])\n",
        "print(training_labels[5500])\n",
        "print(training_images[5500])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   4   3   0   0   0   0  35 140 168\n",
            "  129  70   0   0   0   0   0   0  18   0]\n",
            " [  0   0   0   0   0   0   1   3   1   0   0   0  69 120 212 225 170 182\n",
            "  174 178 163   0   0   0   0 111  58   7]\n",
            " [  0   0   0   0   0   0   0   0   0  35 122 164 187 197  88  29 207 110\n",
            "  188 211 185 168  69   0 123 171   0   0]\n",
            " [  0   3   3   3   3   0   0   0 115 185 173 127 177  79   0 236 157   0\n",
            "    0 214 218 196 196 217 212 214 166   1]\n",
            " [  0   0   0   0   0   0  94 237 197 174  29 156 213   0 120 255  72   0\n",
            "    0   0 172 213 200 223  12 159 221 103]\n",
            " [  0  33  70  13   9   0   0  13 154 176 172  70 223 171   0  90 255 106\n",
            "    2   7   0 178 202 225  96 147 214  79]\n",
            " [  0 163 218 182 166 165 121   0 132 181 180 169 171 202 182 173 194 208\n",
            "  196 200 209 189 180 181 194 193 207  91]\n",
            " [  4  54 109 164 187 196 205 255 210 209 214 219 219 215 223 223 219 217\n",
            "  217 220 223 227 216 218 214 207 255  88]\n",
            " [ 16  67  15   0   0   0   9  26  52  69  96 109 107 100  88  73  62  53\n",
            "   56  46  39  53  51  33  21   2   0   0]\n",
            " [  0   9  49  74  62  87  93  50  28  16   0   0   0   0   0   0   0   0\n",
            "    0   8  45  46  35  38  49  67  81  45]\n",
            " [  1   0   0   0   8  66  97 101 123 136 103  61  61  62  63  57  55  52\n",
            "   61  76 105 114 107 106 105  92  80  23]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "sDX01tuN0drl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "all of the values in the number are between 0 and 255. If we are training a neural network, for various reasons it's easier if we treat all values as between 0 and 1, a process called 'normalizing'...and fortunately in Python it's easy to normalize a list like this without looping. You do it like this:"
      ]
    },
    {
      "metadata": {
        "id": "ErV8QGeeoH4l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_images  = training_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m_DSIkeF0lqM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Sequential: That defines a SEQUENCE of layers in the neural network\n",
        "\n",
        "Flatten: Remember earlier where our images were a square, when you printed them out? Flatten just takes that square and turns it into a 1 dimensional set.\n",
        "\n",
        "Dense: Adds a layer of neurons\n",
        "\n",
        "Each layer of neurons need an activation function to tell them what to do. There's lots of options, but just use these for now.\n",
        "\n",
        "Relu effectively means \"If X>0 return X, else return 0\" -- so what it does it it only passes values 0 or greater to the next layer in the network.\n",
        "\n",
        "Softmax takes a set of values, and effectively picks the biggest one, so, for example, if the output of the last layer looks like [0.1, 0.1, 0.05, 0.1, 9.5, 0.1, 0.05, 0.05, 0.05], it saves you from fishing through it looking for the biggest value, and turns it into [0,0,0,0,1,0,0,0,0] -- The goal is to save a lot of coding!"
      ]
    },
    {
      "metadata": {
        "id": "q45bi5WuSwaZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "start = time. time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WtWxK16hQxLN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Exercise 3: \n",
        "\n",
        "What would happen if you remove the Flatten() layer. Why do you think that's the case? \n",
        "\n",
        "You get an error about the shape of the data. It may seem vague right now, but it reinforces the rule of thumb that the first layer in your network should be the same shape as your data. Right now our data is 28x28 images, and 28 layers of 28 neurons would be infeasible, so it makes more sense to 'flatten' that 28,28 into a 784x1. Instead of wriitng all the code to handle that ourselves, we add the Flatten() layer at the begining, and when the arrays are loaded into the model later, they'll automatically be flattened for us."
      ]
    },
    {
      "metadata": {
        "id": "roHEgnVBk3hu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                      tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                      tf.keras.layers.Dense(10,activation=tf.nn.softmax)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-IKAAFUn0xec",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Compiling model with an optimizer and loss function. "
      ]
    },
    {
      "metadata": {
        "id": "v9LFQGGGoMGd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = tf.train.AdamOptimizer(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tRlRa5nm1Szb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Using callback function to stop the epoch when acc reaches 0.97"
      ]
    },
    {
      "metadata": {
        "id": "bJqjv9kmynhq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')> 0.97):\n",
        "      print(\"\\nReached 97% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U0IC5MWZyzos",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "callbacks = myCallback()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PTm_BnbX1QEr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "''model.fit '' asking it to fit your training data to your training labels -- i.e. have it figure out the relationship between the training data and its actual labels, so in future if you have data that looks like the training data, then it can make a prediction for what that data would look like."
      ]
    },
    {
      "metadata": {
        "id": "JX5CTtSBoeI7",
        "colab_type": "code",
        "outputId": "3bce9b5b-4064-4fe0-e291-742e91f75d8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(training_images, training_labels, epochs=10 ,)# callbacks=[callbacks])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 8s 126us/sample - loss: 0.4971 - acc: 0.8250\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 121us/sample - loss: 0.3764 - acc: 0.8643\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 121us/sample - loss: 0.3366 - acc: 0.8780\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.3137 - acc: 0.8842\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.2957 - acc: 0.8921\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 112us/sample - loss: 0.2821 - acc: 0.8956\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.2670 - acc: 0.9005\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 112us/sample - loss: 0.2577 - acc: 0.9054\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 110us/sample - loss: 0.2488 - acc: 0.9070\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.2376 - acc: 0.9107\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f841109e4e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "55b-XW2gS0t4",
        "colab_type": "code",
        "outputId": "e89049ff-1f05-4242-c235-50149d578be2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "end = time. time()\n",
        "print(end - start)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79.01879715919495\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "82lOplRlojM_",
        "colab_type": "code",
        "outputId": "77681d6f-b080-44b3-b5cc-17b8a8568cf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 61us/sample - loss: 0.3381 - acc: 0.8816\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.33810758605003355, 0.8816]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "6TTvs3u3xIy0",
        "colab_type": "code",
        "outputId": "4cce98fa-7541-43a8-e6bd-e054fde0108c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[2])\n",
        "print(test_labels[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.35784759e-07 9.99999881e-01 2.37683189e-11 4.37287456e-10\n",
            " 8.88522422e-10 9.93181232e-13 7.14728786e-13 6.35227933e-27\n",
            " 1.54605224e-12 1.01429365e-19]\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aab0SD3Ib7Wg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "CREATING A NN WITH HIDDEN LAYER OF 1024  MAKES THE CALCULATION SOPHISTICATED SO IT TAKES MORE TIME BUT GIVES MUCH MORE ACCURACY"
      ]
    },
    {
      "metadata": {
        "id": "_M72G4f6SaSj",
        "colab_type": "code",
        "outputId": "1c36b4bb-7992-459f-91a8-33cc26d5c82b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "start = time. time()\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = tf.train.AdamOptimizer(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=10 )\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 20s 331us/sample - loss: 0.4723 - acc: 0.8291\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 20s 327us/sample - loss: 0.3561 - acc: 0.8713\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 20s 336us/sample - loss: 0.3206 - acc: 0.8812\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 20s 325us/sample - loss: 0.2960 - acc: 0.8897\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 21s 343us/sample - loss: 0.2768 - acc: 0.8967\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 19s 322us/sample - loss: 0.2635 - acc: 0.9019\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 19s 324us/sample - loss: 0.2502 - acc: 0.9069\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 20s 339us/sample - loss: 0.2370 - acc: 0.9111\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 19s 313us/sample - loss: 0.2283 - acc: 0.9140\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 20s 329us/sample - loss: 0.2190 - acc: 0.9171\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f841041e4e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "zt-tfbBUY4YR",
        "colab_type": "code",
        "outputId": "41e32fe9-3721-4692-b1d5-c548df046104",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "end = time. time()\n",
        "print(end - start)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "198.56065487861633\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DvBKIuoRZCb9",
        "colab_type": "code",
        "outputId": "bc48a33b-75a0-47cd-c075-c8e057e0e3f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "model.evaluate(test_images, test_labels)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 2s 164us/sample - loss: 0.3282 - acc: 0.8888\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.32821866466999056, 0.8888]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    }
  ]
}